{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaStImcRParl",
        "outputId": "6a576fc8-8699-4d04-9e73-657682cc64bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtjWT0OuS1ar",
        "outputId": "59cb147e-fc0d-48a2-a6f7-559aabb2e405"
      },
      "outputs": [],
      "source": [
        "# !pip install fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wsMDP9i1VkDB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "# import kans\n",
        "# Train on MNIST\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
        "# import argparse\n",
        "import random\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# # 'KAN' or 'MLP'\n",
        "# parser.add_argument('--model', type=str, default='MLP')\n",
        "# parser.add_argument('--seed', type=int, default=1)\n",
        "# parser.add_argument('--epoch', type=int, default=30)\n",
        "# parser.add_argument('--lr', type=float, default=1e-2)\n",
        "# args = parser.parse_args()\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    # fix seed\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed = 1\n",
        "set_seed(seed)\n",
        "epochs = 1\n",
        "lr = 1e-2\n",
        "\n",
        "# Load MNIST\n",
        "transform   = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "trainset    = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "valset      = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
        "valloader   = DataLoader(valset, batch_size=256, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOU-dzVkS8HJ"
      },
      "source": [
        "## MNIST example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "msuhv0Y8RYiB"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class NaiveFourierKANLayer(nn.Module):\n",
        "    def __init__(self, inputdim, outdim, initial_gridsize, addbias=True):\n",
        "        super(NaiveFourierKANLayer, self).__init__()\n",
        "        self.addbias = addbias\n",
        "        self.inputdim = inputdim\n",
        "        self.outdim = outdim\n",
        "\n",
        "        # Learnable gridsize parameter\n",
        "        self.gridsize_param = nn.Parameter(torch.tensor(initial_gridsize, dtype=torch.float32))\n",
        "\n",
        "        # Fourier coefficients as a learnable parameter with Xavier initialization\n",
        "        self.fouriercoeffs = nn.Parameter(torch.empty(2, outdim, inputdim, initial_gridsize))\n",
        "        nn.init.xavier_uniform_(self.fouriercoeffs)\n",
        "\n",
        "        if self.addbias:\n",
        "            self.bias = nn.Parameter(torch.zeros(1, outdim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        gridsize = torch.clamp(self.gridsize_param, min=1).round().int()\n",
        "        xshp = x.shape\n",
        "        outshape = xshp[:-1] + (self.outdim,)\n",
        "        x = torch.reshape(x, (-1, self.inputdim))\n",
        "        k = torch.reshape(torch.arange(1, gridsize + 1, device=x.device), (1, 1, 1, gridsize))\n",
        "        xrshp = torch.reshape(x, (x.shape[0], 1, x.shape[1], 1))\n",
        "        c = torch.cos(k * xrshp)\n",
        "        s = torch.sin(k * xrshp)\n",
        "        y = torch.sum(c * self.fouriercoeffs[0:1, :, :, :gridsize], (-2, -1))\n",
        "        y += torch.sum(s * self.fouriercoeffs[1:2, :, :, :gridsize], (-2, -1))\n",
        "        if self.addbias:\n",
        "            y += self.bias\n",
        "        y = torch.reshape(y, outshape)\n",
        "        return y\n",
        "\n",
        "class MNISTFourierKAN(nn.Module):\n",
        "    def __init__(self, params_list):\n",
        "        super(MNISTFourierKAN, self).__init__()\n",
        "        self.layer1 = NaiveFourierKANLayer(params_list[0], params_list[1], initial_gridsize=28)\n",
        "        self.layer2 = NaiveFourierKANLayer(params_list[1], params_list[2], initial_gridsize=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7q1rrJM2R-2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l9CHpRIRjyS",
        "outputId": "8a45114d-ad64-4034-c606-a3528b657a7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [05:33<00:00,  1.42s/it, loss=0.117, lr=0.01] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Val Loss: 0.17784138172864913, Val Accuracy: 0.9544921875, avg time:333.7556369304657 s\n",
            "FourierKAN | Averaged Inference Time:3.368061065673828 ms\n",
            "FourierKAN | Params: 5.6301 M\n",
            "| name                         | #elements or shape   |\n",
            "|:-----------------------------|:---------------------|\n",
            "| model                        | 5.6M                 |\n",
            "|  fourierkan1                 |  5.6M                |\n",
            "|   fourierkan1.gridsize_param |   ()                 |\n",
            "|   fourierkan1.fouriercoeffs  |   (2, 128, 784, 28)  |\n",
            "|   fourierkan1.bias           |   (1, 128)           |\n",
            "|  fourierkan2                 |  10.3K               |\n",
            "|   fourierkan2.gridsize_param |   ()                 |\n",
            "|   fourierkan2.fouriercoeffs  |   (2, 10, 128, 4)    |\n",
            "|   fourierkan2.bias           |   (1, 10)            |\n"
          ]
        }
      ],
      "source": [
        "model_str = \"FourierKAN\"\n",
        "\n",
        "# Define model\n",
        "model   = MNISTFourierKAN([28 * 28, 128, 10])\n",
        "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Define optimizer\n",
        "optimizer = optim.LBFGS(model.parameters(), lr=lr)\n",
        "# Define learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "# Define loss\n",
        "criterion     = nn.CrossEntropyLoss()\n",
        "\n",
        "time_list     = []\n",
        "fourier_loss = []\n",
        "for epoch in range(epochs):\n",
        "    # Train\n",
        "    model.train()\n",
        "    sta_time = time.time()\n",
        "    with tqdm(trainloader) as pbar:\n",
        "        for i, (images, labels) in enumerate(pbar):\n",
        "            images, labels = images.view(-1, 28 * 28).to(device), labels.to(device)\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "                output  = model(images)\n",
        "                loss    = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                return loss\n",
        "            optimizer.step(closure)\n",
        "            loss        = closure()\n",
        "            fourier_loss.append(loss.item())\n",
        "            pbar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
        "    end_time = time.time()\n",
        "    time_list.append(end_time-sta_time)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss        = 0\n",
        "    val_accuracy    = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valloader:\n",
        "            images          = images.view(-1, 28 * 28).to(device)\n",
        "            output          = model(images)\n",
        "            val_loss        += criterion(output, labels.to(device)).item()\n",
        "            val_accuracy    += (\n",
        "                (output.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
        "            )\n",
        "    val_loss        /= len(valloader)\n",
        "    val_accuracy    /= len(valloader)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}, avg time:{np.mean(time_list)} s\"\n",
        "    )\n",
        "\n",
        "# toy testing\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "test_x      = valset[0][0].view(-1, 28 * 28)\n",
        "inf_time    = []\n",
        "for i in range(500):\n",
        "    inf_sta_time    =  time.time()\n",
        "    res             = model(test_x)\n",
        "    inf_end_time    =   time.time()\n",
        "    inf_time.append(inf_end_time-inf_sta_time)\n",
        "\n",
        "def print_model_parm_nums(model):\n",
        "    total = sum([param.nelement() for param in model.parameters()])\n",
        "    return (total / 1e6)\n",
        "\n",
        "print(f'{model_str} | Averaged Inference Time:{np.mean(inf_time)*1e3} ms')\n",
        "# flops = FlopCountAnalysis(model, test_x)\n",
        "# print(f\"{model_str} | MACs: %.4f M \" % (flops.total()/ 1e6))\n",
        "print(f\"{model_str} | Params: %.4f M\" % print_model_parm_nums(model))\n",
        "print(parameter_count_table(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PY0O7IkdTtHd"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NaiveLaplaceKANLayer(nn.Module):\n",
        "    def __init__(self, inputdim, outdim, initial_gridsize, addbias=True):\n",
        "        super(NaiveLaplaceKANLayer, self).__init__()\n",
        "        self.addbias = addbias\n",
        "        self.inputdim = inputdim\n",
        "        self.outdim = outdim\n",
        "\n",
        "        # Learnable gridsize parameter\n",
        "        self.gridsize_param = nn.Parameter(torch.tensor(initial_gridsize, dtype=torch.float32))\n",
        "\n",
        "        # Laplace coefficients as a learnable parameter with Xavier initialization\n",
        "        self.laplacecoeffs = nn.Parameter(torch.empty(2, outdim, inputdim, initial_gridsize))\n",
        "        nn.init.xavier_uniform_(self.laplacecoeffs)\n",
        "\n",
        "        if self.addbias:\n",
        "            self.bias = nn.Parameter(torch.zeros(1, outdim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        gridsize = torch.clamp(self.gridsize_param, min=1).round().int()\n",
        "        xshp = x.shape\n",
        "        outshape = xshp[:-1] + (self.outdim,)\n",
        "        x = torch.reshape(x, (-1, self.inputdim))\n",
        "\n",
        "        # Create a grid of lambda values\n",
        "        lambdas = torch.reshape(torch.linspace(0.1, 1., gridsize, device=x.device), (1, 1, 1, gridsize))\n",
        "        xrshp = torch.reshape(x, (x.shape[0], 1, x.shape[1], 1))\n",
        "\n",
        "        # Exponential functions for Laplace transform\n",
        "        exp_neg = torch.exp(-lambdas * xrshp)\n",
        "        exp_pos = torch.exp(lambdas * xrshp)\n",
        "\n",
        "        # Applying Laplace coefficients to the input\n",
        "        y = torch.sum(exp_neg * self.laplacecoeffs[0:1, :, :, :gridsize], (-2, -1))\n",
        "        y += torch.sum(exp_pos * self.laplacecoeffs[1:2, :, :, :gridsize], (-2, -1))\n",
        "\n",
        "        if self.addbias:\n",
        "            y += self.bias\n",
        "        y = torch.reshape(y, outshape)\n",
        "        return y\n",
        "\n",
        "class MNISTLaplaceKAN(nn.Module):\n",
        "    def __init__(self, params_list):\n",
        "        super(MNISTLaplaceKAN, self).__init__()\n",
        "        self.layer1 = NaiveLaplaceKANLayer(params_list[0], params_list[1], initial_gridsize=28)\n",
        "        self.layer2 = NaiveLaplaceKANLayer(params_list[1], params_list[2], initial_gridsize=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r7EBjSnQT351"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [05:33<00:00,  1.42s/it, loss=0.197, lr=0.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Val Loss: 0.2669198980322108, Val Accuracy: 0.923828125, avg time:333.10927748680115 s\n",
            "LaplaceKAN | Averaged Inference Time:2.9441170692443848 ms\n",
            "LaplaceKAN | Params: 5.6301 M\n",
            "| name                         | #elements or shape   |\n",
            "|:-----------------------------|:---------------------|\n",
            "| model                        | 5.6M                 |\n",
            "|  fourierkan1                 |  5.6M                |\n",
            "|   fourierkan1.gridsize_param |   ()                 |\n",
            "|   fourierkan1.laplacecoeffs  |   (2, 128, 784, 28)  |\n",
            "|   fourierkan1.bias           |   (1, 128)           |\n",
            "|  fourierkan2                 |  10.3K               |\n",
            "|   fourierkan2.gridsize_param |   ()                 |\n",
            "|   fourierkan2.laplacecoeffs  |   (2, 10, 128, 4)    |\n",
            "|   fourierkan2.bias           |   (1, 10)            |\n"
          ]
        }
      ],
      "source": [
        "model_str = \"LaplaceKAN\"\n",
        "\n",
        "# Define model\n",
        "model   = MNISTLaplaceKAN([28 * 28, 128, 10])\n",
        "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Define optimizer\n",
        "optimizer = optim.LBFGS(model.parameters(), lr=lr)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# Define learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "# Define loss\n",
        "criterion     = nn.CrossEntropyLoss()\n",
        "\n",
        "time_list     = []\n",
        "laplace_loss = []\n",
        "for epoch in range(epochs):\n",
        "    # Train\n",
        "    model.train()\n",
        "    sta_time = time.time()\n",
        "    with tqdm(trainloader) as pbar:\n",
        "        for i, (images, labels) in enumerate(pbar):\n",
        "            images, labels = images.view(-1, 28 * 28).to(device), labels.to(device)\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "                output  = model(images)\n",
        "                loss    = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                return loss\n",
        "            optimizer.step(closure)\n",
        "            loss        = closure()\n",
        "            laplace_loss.append(loss.item())\n",
        "            pbar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
        "    end_time = time.time()\n",
        "    time_list.append(end_time-sta_time)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss        = 0\n",
        "    val_accuracy    = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valloader:\n",
        "            images          = images.view(-1, 28 * 28).to(device)\n",
        "            output          = model(images)\n",
        "            val_loss        += criterion(output, labels.to(device)).item()\n",
        "            val_accuracy    += (\n",
        "                (output.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
        "            )\n",
        "    val_loss        /= len(valloader)\n",
        "    val_accuracy    /= len(valloader)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}, avg time:{np.mean(time_list)} s\"\n",
        "    )\n",
        "\n",
        "# toy testing\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "test_x      = valset[0][0].view(-1, 28 * 28)\n",
        "inf_time    = []\n",
        "for i in range(500):\n",
        "    inf_sta_time    =  time.time()\n",
        "    res             = model(test_x)\n",
        "    inf_end_time    =   time.time()\n",
        "    inf_time.append(inf_end_time-inf_sta_time)\n",
        "\n",
        "def print_model_parm_nums(model):\n",
        "    total = sum([param.nelement() for param in model.parameters()])\n",
        "    return (total / 1e6)\n",
        "\n",
        "print(f'{model_str} | Averaged Inference Time:{np.mean(inf_time)*1e3} ms')\n",
        "# flops = FlopCountAnalysis(model, test_x)\n",
        "# print(f\"{model_str} | MACs: %.4f M \" % (flops.total()/ 1e6))\n",
        "print(f\"{model_str} | Params: %.4f M\" % print_model_parm_nums(model))\n",
        "print(parameter_count_table(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pZgwtvjWbKDN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class NaiveWaveletKANLayer(nn.Module):\n",
        "    def __init__(self, inputdim, outdim, initial_gridsize, addbias=True):\n",
        "        super(NaiveWaveletKANLayer, self).__init__()\n",
        "        self.addbias = addbias\n",
        "        self.inputdim = inputdim\n",
        "        self.outdim = outdim\n",
        "\n",
        "        # Learnable gridsize parameter\n",
        "        self.gridsize_param = nn.Parameter(torch.tensor(initial_gridsize, dtype=torch.float32))\n",
        "\n",
        "        # Wavelet coefficients as a learnable parameter with Xavier initialization\n",
        "        self.waveletcoeffs = nn.Parameter(torch.empty(2, outdim, inputdim, initial_gridsize))\n",
        "        nn.init.xavier_uniform_(self.waveletcoeffs)\n",
        "\n",
        "        if self.addbias:\n",
        "            self.bias = nn.Parameter(torch.zeros(1, outdim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        gridsize = torch.clamp(self.gridsize_param, min=1).round().int()\n",
        "        xshp = x.shape\n",
        "        outshape = xshp[:-1] + (self.outdim,)\n",
        "        x = torch.reshape(x, (-1, self.inputdim))\n",
        "\n",
        "        # Create a range of scales and translations for the wavelet\n",
        "        scales = torch.linspace(1, gridsize, gridsize, device=x.device).unsqueeze(0).unsqueeze(0).unsqueeze(0)\n",
        "        translations = torch.linspace(0, 1, gridsize, device=x.device).unsqueeze(0).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # Morlet wavelet calculations\n",
        "        xrshp = torch.reshape(x, (x.shape[0], 1, x.shape[1], 1))\n",
        "        u = (xrshp - translations) * scales\n",
        "        real = torch.cos(np.pi*u) * torch.exp(-u**2 /2.)\n",
        "        imag = torch.sin(np.pi*u) * torch.exp(-u**2 /2.)\n",
        "\n",
        "        # Apply wavelet coefficients to the wavelet transform outputs\n",
        "        y_real = torch.sum(real * self.waveletcoeffs[0:1, :, :, :gridsize], (-2, -1))\n",
        "        y_imag = torch.sum(imag * self.waveletcoeffs[1:2, :, :, :gridsize], (-2, -1))\n",
        "        y = y_real + y_imag\n",
        "\n",
        "        if self.addbias:\n",
        "            y += self.bias\n",
        "        y = torch.reshape(y, outshape)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MR_BbxqHvVuN"
      },
      "outputs": [],
      "source": [
        "class MNISTwaveKAN(nn.Module):\n",
        "    def __init__(self, params_list):\n",
        "        super(MNISTwaveKAN, self).__init__()\n",
        "        self.layer1 = NaiveWaveletKANLayer(params_list[0], params_list[1], initial_gridsize=28)\n",
        "        self.layer2 = NaiveWaveletKANLayer(params_list[1], params_list[2], initial_gridsize=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9ZoGQzIbwKlZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/235 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [05:38<00:00,  1.44s/it, loss=0.272, lr=0.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Val Loss: 0.42337609380483626, Val Accuracy: 0.87265625, avg time:338.4516031742096 s\n",
            "MNISTwaveKAN | Averaged Inference Time:3.838697910308838 ms\n",
            "MNISTwaveKAN | Params: 5.6301 M\n",
            "| name                         | #elements or shape   |\n",
            "|:-----------------------------|:---------------------|\n",
            "| model                        | 5.6M                 |\n",
            "|  fourierkan1                 |  5.6M                |\n",
            "|   fourierkan1.gridsize_param |   ()                 |\n",
            "|   fourierkan1.waveletcoeffs  |   (2, 128, 784, 28)  |\n",
            "|   fourierkan1.bias           |   (1, 128)           |\n",
            "|  fourierkan2                 |  10.3K               |\n",
            "|   fourierkan2.gridsize_param |   ()                 |\n",
            "|   fourierkan2.waveletcoeffs  |   (2, 10, 128, 4)    |\n",
            "|   fourierkan2.bias           |   (1, 10)            |\n"
          ]
        }
      ],
      "source": [
        "model_str = \"MNISTwaveKAN\"\n",
        "\n",
        "# Define model\n",
        "model   = MNISTwaveKAN([28 * 28, 128, 10])\n",
        "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Define optimizer\n",
        "optimizer = optim.LBFGS(model.parameters(), lr=lr)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# Define learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "# Define loss\n",
        "criterion     = nn.CrossEntropyLoss()\n",
        "\n",
        "time_list     = []\n",
        "wavelet_loss = []\n",
        "for epoch in range(epochs):\n",
        "    # Train\n",
        "    model.train()\n",
        "    sta_time = time.time()\n",
        "    with tqdm(trainloader) as pbar:\n",
        "        for i, (images, labels) in enumerate(pbar):\n",
        "            images, labels = images.view(-1, 28 * 28).to(device), labels.to(device)\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "                output  = model(images)\n",
        "                loss    = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                return loss\n",
        "            optimizer.step(closure)\n",
        "            loss        = closure()\n",
        "            wavelet_loss.append(loss.item())\n",
        "            pbar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
        "    end_time = time.time()\n",
        "    time_list.append(end_time-sta_time)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss        = 0\n",
        "    val_accuracy    = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valloader:\n",
        "            images          = images.view(-1, 28 * 28).to(device)\n",
        "            output          = model(images)\n",
        "            val_loss        += criterion(output, labels.to(device)).item()\n",
        "            val_accuracy    += (\n",
        "                (output.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
        "            )\n",
        "    val_loss        /= len(valloader)\n",
        "    val_accuracy    /= len(valloader)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}, avg time:{np.mean(time_list)} s\"\n",
        "    )\n",
        "\n",
        "# toy testing\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "test_x      = valset[0][0].view(-1, 28 * 28)\n",
        "inf_time    = []\n",
        "for i in range(500):\n",
        "    inf_sta_time    =  time.time()\n",
        "    res             = model(test_x)\n",
        "    inf_end_time    =   time.time()\n",
        "    inf_time.append(inf_end_time-inf_sta_time)\n",
        "\n",
        "def print_model_parm_nums(model):\n",
        "    total = sum([param.nelement() for param in model.parameters()])\n",
        "    return (total / 1e6)\n",
        "\n",
        "print(f'{model_str} | Averaged Inference Time:{np.mean(inf_time)*1e3} ms')\n",
        "# flops = FlopCountAnalysis(model, test_x)\n",
        "# print(f\"{model_str} | MACs: %.4f M \" % (flops.total()/ 1e6))\n",
        "print(f\"{model_str} | Params: %.4f M\" % print_model_parm_nums(model))\n",
        "print(parameter_count_table(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg7aa6jYwSoy"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.plot(fourier_loss,label='fourier')\n",
        "plt.plot(laplace_loss,label='laplace')\n",
        "plt.plot(wavelet_loss,label='wavelet')\n",
        "plt.title('Training Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iter')\n",
        "plt.ylim([0,2])\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
